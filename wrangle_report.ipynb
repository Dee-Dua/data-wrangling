{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "### (Internal Document)\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Data Gathering](#gathering)\n",
    "- [Data Assessing and Cleaning](#assessing_cleaning)\n",
    "- [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "My goal for this project is to wrangle WeRateDogs Twitter data to create analyses and visualizations. \n",
    "WeRateDogs is a Professional Dog rating service which rates people's dogs with a humorous comment about the dog.\n",
    "Using Python and its libraries, I have gathered data from a variety of sources and in a variety of formats, to assess its quality and tidiness, then clean it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gathering'></a>\n",
    "## Data Gathering\n",
    "\n",
    "I have gathered data from 3 sources:\n",
    "\n",
    "- Twitter archive shared by WeRateDogs, that was downloaded from their Twitter archive. This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for 2356 tweets in a comma separated value file.\n",
    "\n",
    "- Tweet image predictions in a tab separated value file. This file contains predictions about what breed of dog (or other object, animal, etc.) id present in each tweet image according to a neural network that can classify breeds of dogs. The file contains image predictions (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images).\n",
    "\n",
    "- Retweet count and favorite (\"like\") count for each tweet in the WeRateDogs Twitter archive. I queried the Twitter API for each tweet's JSON data using Python's Tweepy library and built a Pandas dataframe using the tweet ID, retweet count, and favourite count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing_cleaning'></a>\n",
    "## Data Assessing and Cleaning\n",
    "\n",
    "I assessed the data for quality and tidiniess issues and have performed the following cleaning activities:\n",
    "\n",
    "- Since we are only concerned with the original tweets, I deleted all the rows that are retweets by querying the \"retweeted_status_id\" column for values. *df_twitter.retweeted_status_id.isnull() == False*\n",
    "- I dropped columns that are related to retweets \"retweeted_status_id\", \"retweeted_status_user_id\", \"retweeted_status_timestamp\"\n",
    "- I also dropped columns \"in_reply_to_status_id\", \"in_reply_to_user_id\" to clean up the dataframe since I won't be using these columns.\n",
    "- I updated the \"source\" column to make it easier to read.\n",
    "- I converted timestamp column to datetime datatype instead of object datatype.\n",
    "- I converted \"tweet_id\" column to Object from int, since it's not a numeric field.\n",
    "- I converted datatype of 'retweet_count' and 'favourite_count to integer and replaced the null values with zero.\n",
    "- i checked Ratings for incorrectly extracted ratings from the text and dropped them (30 records). I also checked for ratings that didn't have a 10 as the denominator and dropped them to get a dataset with a consistent denominator (16 records).\n",
    "\n",
    "- I combined 'doggo', 'puppo', 'floofer', 'pupper' columns into one column for the stage of the dog. The 4 stages can be considered as 4 values of the \"stage\" variable. Since a dog can be tagged for multiple stages, I have updated the stage column with comma separated values and \"None\" for dogs that have no stage specified. I also dropped the 4 columns \"doggo\", \"puppo\", \"floofer\", \"pupper\".\n",
    "- I merged df_twitter (DataFrame containing the Twitter archive) and df_img (DataFrame containing the tweet image predictions) by performing a left join, i.e. keeping all records from df_twitter. I created a \"df_combined\" DataFrame for this merged data.\n",
    "- I merged df_combined and df_tweet (DataFrame containing data extracted using the Twitter API). I performed a left join, i.e. keeping all records from df_combined. I stored this merged data in \"df_final\" DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'></a>\n",
    "## References\n",
    "\n",
    "- https://stackoverflow.com\n",
    "- https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
